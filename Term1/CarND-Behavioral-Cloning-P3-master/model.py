#!/usr/bin/python
## Author: kishore
## Date: JUNE, 04,2017
# model to train the data

import tensorflow as tf
from keras.layers import Dense, Flatten, Lambda, Activation, MaxPooling2D
from keras.layers.convolutional import Convolution2D
from keras.models import Sequential
from keras.optimizers import Adam
import json
import errno
import cv2
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy.misc
from scipy.ndimage import rotate
from scipy.stats import bernoulli

##############################################variable declaration ################################################

# Some useful constants
dataPath = './driving_log.csv'
imPath = './'

# As most of the steering angle is zero a constant value added for better training results.
STEERING_CONSTANT = 0.228

tf.python.control_flow_ops = tf


#variable for trainig the data.
number_of_epochs = 8
number_of_samples_per_epoch = 20032
number_of_validation_samples = 6400
learning_rate = 1e-4
activation_relu = 'relu'

############################################################ END ##########################################################


################################################################ Preprocessing the data ###################################


def crop(image, top_percent, bottom_percent):
    """
     Crops the images according to the top and bottom percentages

    :return:
        The cropped image
    """
    assert 0 <= top_percent < 0.5, 'top_percent should be between 0.0 and 0.5'
    assert 0 <= bottom_percent < 0.5, 'top_percent should be between 0.0 and 0.5'

    top = int(np.ceil(image.shape[0] * top_percent))
    bottom = image.shape[0] - int(np.ceil(image.shape[0] * bottom_percent))

    return image[top:bottom, :]

def randomFlip(image, steering_angle, flipping_prob=0.5):
    """
    Image will be flipped with 0.5 probability and steering angle is modified or negated with -1 if filp happends  
    
	Input parameters: image , steering angle , flipping probability 
	output parameters: New image and new steering angle
	
	"""
    head = bernoulli.rvs(flipping_prob)
    if head:
        return np.fliplr(image), -1 * steering_angle
    else:
        return image, steering_angle

def resize(image, new_dim):
    """
    Resize a given image according the the new dimension

    Input parameters:  image and resized parameters
	output parameters: resized image
    """
    return scipy.misc.imresize(image, new_dim)

def randomShear(image, steering_angle, shear_range=200):
    """
    Source: https://medium.com/@ksakmann/behavioral-cloning-make-a-car-drive-like-yourself-dc6021152713#.7k8vfppvk

    :param image:
        Source image on which the shear operation will be applied
    :param steering_angle:
        The steering angle of the image
    :param shear_range:
        Random shear between [-shear_range, shear_range + 1] will be applied

    :return:
        The image generated by applying random shear on the source image
    """
    rows, cols, ch = image.shape
    dx = np.random.randint(-shear_range, shear_range + 1)
    random_point = [cols / 2 + dx, rows / 2]
    pts1 = np.float32([[0, rows], [cols, rows], [cols / 2, rows / 2]])
    pts2 = np.float32([[0, rows], [cols, rows], random_point])
    dsteering = dx / (rows / 2) * 360 / (2 * np.pi * 25.0) / 6.0
    M = cv2.getAffineTransform(pts1, pts2)
    image = cv2.warpAffine(image, M, (cols, rows), borderMode=1)
    steering_angle += dsteering

    return image, steering_angle				

def randomGamma(image):
    """
    Random gamma correction is used as an alternative method changing the brightness of
    training images.
    http://www.pyimagesearch.com/2015/10/05/opencv-gamma-correction/

    :param image:
        Source image

    :return:
        New image generated by applying gamma correction to the source image
    """
    gamma = np.random.uniform(0.4, 1.5)
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255
                      for i in np.arange(0, 256)]).astype("uint8")

    # apply gamma correction using the lookup table
    return cv2.LUT(image, table)


def fetchImages(batch_size=64):
    """
    From the three different steering angle (left, center, and right) randomly one of the three will be picked and also 
	images are picked for the batch preparation
   
    :param batch_size:
	
        Hardcoded to 64

    :return:
        An list of selected i.e image files names corresponding steering angles
    """
    data = pd.read_csv(dataPath)
    num_of_img = len(data)
    rnd_indices = np.random.randint(0, num_of_img, batch_size)
    image_files_and_angles = []
    for index in rnd_indices:
        rnd_image = np.random.randint(0, 3)
        if rnd_image == 0:
            img = data.iloc[index]['left'].strip()
            angle = data.iloc[index]['steering'] + STEERING_CONSTANT
            image_files_and_angles.append((img, angle))

        elif rnd_image == 1:
            img = data.iloc[index]['center'].strip()
            angle = data.iloc[index]['steering']
            image_files_and_angles.append((img, angle))
        else:
            img = data.iloc[index]['right'].strip()
            angle = data.iloc[index]['steering'] - STEERING_CONSTANT
            image_files_and_angles.append((img, angle))

    return image_files_and_angles	

def processGenerateImageAngle(image, steering_angle, top_crop_percent=0.35, bottom_crop_percent=0.1,
                       resize_dim=(64, 64), do_shear_prob=0.9):

    """
    The image will be processed and returns the steering angle modified 
 
    :param  input: image,steering_angle, crop percentages, resize dimensions, shear probability. :
    below the flow how the image processing happens.   
    
	randomShear -->crop -->  randomFlip --> randomGamma -->resize
    
	:return:processed image, steering angle
	
    """


    # shear image
    if(bernoulli.rvs(do_shear_prob)):
        image, steering_angle = randomShear(image, steering_angle)

    # crop image
    image = crop(image, top_crop_percent, bottom_crop_percent)

    # flip the image
    image, steering_angle = randomFlip(image, steering_angle)

    # random gamma
    image = randomGamma(image)

    # resize
    image = resize(image, resize_dim)

    return image, steering_angle

def genBatch(batch_size=64):
    """
    This generator will yeild the next batch which is already preprocessed

    :param batch_size:
        Hardcoded to 64
		
    :return:
        A tuple of features and steering angles as two numpy arrays
    """
    while True:
        X_batch = []
        y_batch = []
        images = fetchImages(batch_size)
        for img_file, angle in images:
            raw_image = plt.imread(imPath + img_file)
            raw_angle = angle
            new_image, new_angle = processGenerateImageAngle(raw_image, raw_angle)
            X_batch.append(new_image)
            y_batch.append(new_angle)

        assert len(X_batch) == batch_size, 'len(X_batch) == batch_size should be True'

        yield np.array(X_batch), np.array(y_batch)

############################################################ END ##########################################################


########################################################### TRAINING THE MODEL ###############################################


# model is based on NVIDIA's "End to End Learning for Self-Driving Cars" paper
model = Sequential()

#Normalizing the data
model.add(Lambda(lambda x: x / 127.5 - 1.0, input_shape=(64, 64, 3)))

# Next convolutional and maxpooling layer
model.add(Convolution2D(24, 5, 5, border_mode='same', subsample=(2, 2)))
model.add(Activation(activation_relu))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))

# Next convolutional and maxpooling layer
model.add(Convolution2D(36, 5, 5, border_mode='same', subsample=(2, 2)))
model.add(Activation(activation_relu))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))

# Next convolutional and maxpooling layer
model.add(Convolution2D(48, 5, 5, border_mode='same', subsample=(2, 2)))
model.add(Activation(activation_relu))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))

# Next convolutional and maxpooling layer
model.add(Convolution2D(64, 3, 3, border_mode='same', subsample=(1, 1)))
model.add(Activation(activation_relu))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))

# Next convolutional and maxpooling layer
model.add(Convolution2D(64, 3, 3, border_mode='same', subsample=(1, 1)))
model.add(Activation(activation_relu))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))

model.add(Flatten())

# Next,fully connected layer
model.add(Dense(1164))
model.add(Activation(activation_relu))

# Next,fully connected layer
model.add(Dense(100))
model.add(Activation(activation_relu))

# Next,fully connected layer
model.add(Dense(50))
model.add(Activation(activation_relu))

# Next,fully connected layer
model.add(Dense(10))
model.add(Activation(activation_relu))

# Next,fully connected layer
model.add(Dense(1))

model.summary()

# save the model achitecture
json_string = model.to_json()
with open('model.json', 'w') as outfile:
    json.dump(json_string, outfile)
	
#compile using adams optimizer	
model.compile(optimizer=Adam(learning_rate), loss="mse", )

# create two generators for training and validation
trainGenerator = genBatch()
valGenerator = genBatch()

#training and validating the data
history = model.fit_generator(trainGenerator,
                              samples_per_epoch=number_of_samples_per_epoch,
                              nb_epoch=number_of_epochs,
                              validation_data=valGenerator,
                              nb_val_samples=number_of_validation_samples,
                              verbose=1)

# saving the model and weights 
model.save_weights('weights.h5')
model.save('model.h5')
#################################################################END #################################################